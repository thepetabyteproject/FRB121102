{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make cumulative corner plot by reading mcmc posteriors for all the fitted bursts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emcee.autocorr import AutocorrError\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import emcee\n",
    "import pandas as pd\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiometer(tsys, gain, bandwidth, time, npol=2):\n",
    "    return tsys / gain / np.sqrt(npol * bandwidth * time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples2params(samples, meta_info):\n",
    "    fraction = np.sum(samples[:, 4] / samples[:, 5] < 6) / samples.shape[0]\n",
    "    print(f\"tau fraction {fraction:.3f}\")\n",
    "    if fraction > 0.5:\n",
    "        print(\"Using tau\")\n",
    "        use_tau = True\n",
    "        mask = samples[:, 4] / samples[:, 5] < 6\n",
    "        samples = samples[mask, :]\n",
    "    else:\n",
    "        use_tau = False\n",
    "        mask = samples[:, 4] / samples[:, 5] > 6\n",
    "        samples = np.delete(samples, 5, 1)\n",
    "        samples = samples[mask, :]\n",
    "\n",
    "    samples[:, 0] = (\n",
    "        meta_info[\"fileheader\"][\"fch1\"]\n",
    "        + samples[:, 0] * meta_info[\"fileheader\"][\"native_foff\"]\n",
    "    )\n",
    "    samples[:, 1] *= np.abs(meta_info[\"fileheader\"][\"native_foff\"])\n",
    "    samples[:, 2] *= (\n",
    "        radiometer(\n",
    "            27, 10, 2.355 * samples[:, 1] * 1e6, meta_info[\"fileheader\"][\"native_tsamp\"]\n",
    "        )\n",
    "        * 81.92e-3\n",
    "        / np.sqrt(64 - sum(meta_info[\"mask\"]))\n",
    "    )\n",
    "    samples[:, 3] = (\n",
    "        (samples[:, 3] + meta_info[\"nstart\"])\n",
    "        * meta_info[\"fileheader\"][\"native_tsamp\"]\n",
    "        / 3600\n",
    "        / 24\n",
    "    ) + meta_info[\"fileheader\"][\"tstart\"]\n",
    "    samples[:, 4] *= meta_info[\"fileheader\"][\"native_tsamp\"] * 1e3\n",
    "    if use_tau:\n",
    "        samples[:, 5] *= meta_info[\"fileheader\"][\"native_tsamp\"] * 1e3 * 81.92e-3\n",
    "        samples[:, 5] *= (1000 / meta_info[\"fileheader\"][\"fch1\"]) ** (-4)\n",
    "\n",
    "    param_list = [\n",
    "        r\"$\\mu_f$ (MHz)\",\n",
    "        r\"$\\sigma_f$ (MHz)\",\n",
    "        r\"$S$ (Jy ms)\",\n",
    "        r\"$\\mu_t$ (ms)\",\n",
    "        r\"$\\sigma_t$ (ms)\",\n",
    "    ]\n",
    "    if use_tau:\n",
    "        param_list += [r\"$\\tau$ (ms)\"]\n",
    "\n",
    "    param_list += [r\"DM (pc cm$^{-3}$)\"]\n",
    "    return samples, param_list, mask\n",
    "\n",
    "\n",
    "def get_chains_and_parameters(h5_filename, json_filename, thin=1):\n",
    "    reader = emcee.backends.HDFBackend(h5_filename)\n",
    "\n",
    "    try:\n",
    "        tau = reader.get_autocorr_time()\n",
    "        burnin = int(2 * np.max(tau))\n",
    "        print(f\"burnin using tau is: {burnin}\")\n",
    "        samples = reader.get_chain(discard=burnin, flat=True, thin=thin)\n",
    "\n",
    "    except (AutocorrError, ValueError):\n",
    "#         return None, None\n",
    "        samples = reader.get_chain(discard=0, flat=True, thin=thin)\n",
    "        burnin = int(samples.shape[0] * 0.75)\n",
    "        samples = samples[burnin:, :]\n",
    "        \n",
    "    print(\"burn-in: {0}\".format(burnin))\n",
    "    print(\"flat chain shape: {0}\".format(samples.shape))\n",
    "\n",
    "    with open(json_filename, \"r\") as f:\n",
    "        meta_info = json.loads(f.read())\n",
    "\n",
    "    if samples.shape[-1] == 7:\n",
    "        samples, param_list, _ = samples2params(samples, meta_info)\n",
    "        return samples, param_list\n",
    "    elif samples.shape[-1] == 14:\n",
    "        first_samples, first_params, mask1 = samples2params(samples[:, :7], meta_info)\n",
    "        second_samples, second_params, mask2 = samples2params(\n",
    "            samples[mask1, 7:], meta_info\n",
    "        )\n",
    "        #         print(first_samples[mask2].shape, first_params)\n",
    "        #         print(second_samples.shape, second_params)\n",
    "        param_list = []\n",
    "        for index, param in enumerate(first_params):\n",
    "            param_list.append(param + str(1))\n",
    "        for index, param in enumerate(second_params):\n",
    "            param_list.append(param + str(2))\n",
    "        return (np.hstack([first_samples[mask2], second_samples]), param_list)\n",
    "    else:\n",
    "        first_samples, first_params, mask1 = samples2params(samples[:, :7], meta_info)\n",
    "        second_samples, second_params, mask2 = samples2params(\n",
    "            samples[mask1, 7:14], meta_info\n",
    "        )\n",
    "        third_samples, third_params, mask3 = samples2params(\n",
    "            samples[mask2, 14:], meta_info\n",
    "        )\n",
    "        param_list = []\n",
    "        for index, param in enumerate(first_params):\n",
    "            param_list.append(param + str(1))\n",
    "        for index, param in enumerate(second_params):\n",
    "            param_list.append(param + str(2))\n",
    "        for index, param in enumerate(third_params):\n",
    "            param_list.append(param + str(3))\n",
    "        #         for index, param in enumerate(first_params + second_params + third_params):\n",
    "        #             param_list.append(param + str(((index // 7) + 1)))\n",
    "        return (\n",
    "            np.hstack(\n",
    "                [\n",
    "                    first_samples[mask2, :][mask3, :],\n",
    "                    second_samples[mask3, :],\n",
    "                    third_samples,\n",
    "                ]\n",
    "            ),\n",
    "            param_list,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"121102_paper/mcmc_final/\"\n",
    "cids = [x.split(\"/\")[-1][:-11] for x in glob.glob(PATH + \"*.h5\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_or_move_ahead_thin(cand_id):\n",
    "    rng = np.random.RandomState(2021)\n",
    "    try:\n",
    "        h5_filename = PATH + cand_id + \"_samples.h5\"\n",
    "        json_filename = PATH + cand_id + \".json\"\n",
    "        samples, param_list = get_chains_and_parameters(h5_filename, json_filename, \n",
    "                                                        thin=1)\n",
    "        \n",
    "        random_samples = np.zeros((1000, samples.shape[1]))\n",
    "        for i in range(samples.shape[1]):\n",
    "            random_samples[:, i] = rng.choice(samples[:, i], size=1000, replace=False)\n",
    "\n",
    "        samples = random_samples\n",
    "        \n",
    "        if not np.any(samples):\n",
    "            return np.empty((0, 7))\n",
    "        \n",
    "        nps = samples.shape[1]\n",
    "        if nps == 7:\n",
    "            s = samples\n",
    "        elif nps > 7:\n",
    "            first_comp, second_comp, third_comp = False, False, False\n",
    "            for p in param_list:\n",
    "                if '$\\\\tau$ (ms)1' in p:\n",
    "                    first_comp = True\n",
    "                if '$\\\\tau$ (ms)2' in p:\n",
    "                    second_comp = True\n",
    "                if '$\\\\tau$ (ms)3' in p:\n",
    "                    third_comp = True\n",
    "            s = np.empty((0, 7))\n",
    "            if first_comp and second_comp and third_comp:\n",
    "                s = np.concatenate((s, samples[:, :7]), axis=0)\n",
    "                s = np.concatenate((s, samples[:, 7:14]), axis=0)\n",
    "                s = np.concatenate((s, samples[:, 14:]), axis=0)\n",
    "            elif first_comp and second_comp and not third_comp:\n",
    "                s = np.concatenate((s, samples[:, :7]), axis=0)\n",
    "                s = np.concatenate((s, samples[:, 7:14]), axis=0)\n",
    "            elif second_comp and third_comp and not first_comp:\n",
    "                s = np.concatenate((s, samples[:, 6:13]), axis=0)\n",
    "                s = np.concatenate((s, samples[:, 13:]), axis=0)\n",
    "            elif first_comp and third_comp and not second_comp:\n",
    "                s = np.concatenate((s, samples[:, :7]), axis=0)\n",
    "                s = np.concatenate((s, samples[:, 13:]), axis=0)                \n",
    "            elif first_comp and not second_comp and not third_comp:\n",
    "                s = np.concatenate((s, samples[:, :7]), axis=0)   \n",
    "            elif second_comp and not first_comp and not third_comp:\n",
    "                s = np.concatenate((s, samples[:, 6:13]), axis=0)   \n",
    "            elif third_comp and not first_comp and not second_comp:\n",
    "                s = np.concatenate((s, samples[:, 12:]), axis=0)   \n",
    "            else:\n",
    "                s = np.empty((0, 7))\n",
    "        #     s = s[1:, :]\n",
    "        else:\n",
    "            s = np.empty((0, 7))\n",
    "        print(cand_id, samples.shape, s.shape)\n",
    "        return s\n",
    "    except FileNotFoundError as e:\n",
    "        return cand_id, \"FileNotFoundError\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bursts_bary = pd.read_csv('../data/all_bursts_bary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (all_bursts_bary['use_fluence'] == True) & (all_bursts_bary['fit_method'] == 'mcmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cids_use_f = list(set(all_bursts_bary[m].cand_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "samples_thinned = Parallel(n_jobs=20)(delayed(try_or_move_ahead_thin)(cid) \n",
    "                                      for cid in tqdm(cids_use_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_thinned = np.concatenate(samples_thinned, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('samples_thousand.npy', 'wb') as f:\n",
    "    np.save(f, samples_thinned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('samples_thousand.npy', 'rb') as f:\n",
    "    a = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_plot = np.take(a, indices=[0, 1, 2, 4, 5, 6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = [ r\"$\\mu_f$ (MHz)\", r\"$\\sigma_f$ (MHz)\",r\"$\\log_{10}$(S (Jy ms))\", \n",
    "              r\"$\\log_{10}$($\\sigma_t$ (ms))\", r\"$\\tau$ (ms)\", \n",
    "              r\"DM (pc cm$^{-3}$)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainconsumer import ChainConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_plot_new = samples_plot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = {}\n",
    "ext[r\"$\\mu_f$ (MHz)\"] = (800, 2200)\n",
    "ext[r\"$\\sigma_f$ (MHz)\"] = (0, 1000)\n",
    "ext[r\"$\\log_{10}$(S (Jy ms))\"] = (-2, 1.5)\n",
    "ext[r\"$\\log_{10}$($\\sigma_t$ (ms))\"] = (-1.5, 1)\n",
    "ext[r\"$\\tau$ (ms)\"] = (0, 4)\n",
    "ext[r\"DM (pc cm$^{-3}$)\"] = (500, 650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ChainConsumer()\n",
    "c.add_chain(samples_plot_new, parameters=param_list)\n",
    "corner_plot_path = \"./\"\n",
    "# corner_plot_path += \"mcmc_final/final_corner_plots/\"\n",
    "with plt.style.context(['science']):\n",
    "    fig = c.plotter.plot(\n",
    "        figsize=\"grow\",\n",
    "        filename=corner_plot_path + 'cumulative_corner_plot' + \".pdf\",\n",
    "        display=False, extents=ext\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number(x, dx):\n",
    "    \"\"\" Returns a string of the measurement value\"\"\"\n",
    "    \"\"\" together with the measurement error\"\"\"\n",
    "    \"\"\" x: measurement value\"\"\"\n",
    "    \"\"\" dx: measurment error\"\"\"\n",
    "\n",
    "    # Power of dx\n",
    "    power_err = np.log10(dx)\n",
    "\n",
    "    # Digits of dx in format a.bcd\n",
    "    n_err = dx / (10**np.floor(power_err))\n",
    "\n",
    "    # If the second digit in dx is >=5\n",
    "    # round the 1st digit in dx up\n",
    "    if n_err % 1 >= 0.5:\n",
    "        # If the first digit of dx is 9\n",
    "        # the precision is one digit less\n",
    "        if int(n_err) == 9: \n",
    "            err = 1\n",
    "        # The precision of x is determined by the precision of dx\n",
    "            prec=int(-np.floor(np.log10(dx))) - 1           \n",
    "        else:\n",
    "            err = np.ceil(n_err)\n",
    "            # The precision of x is determined by the precision of dx\n",
    "            prec=int(-np.floor(np.log10(dx)))\n",
    "    # Otherwise round down\n",
    "    else:      \n",
    "        err = np.floor(n_err) \n",
    "        # The precision of x is determined by the precision of dx\n",
    "        prec=int(-np.floor(np.log10(dx)))\n",
    "    return x, err, prec\n",
    "\n",
    "def get_err_string(x, le, ue):\n",
    "    min_err = min(le, ue)\n",
    "    x, err, prec = get_number(x, min_err)\n",
    "    s = ''\n",
    "    if min_err > 1:\n",
    "        s += str(int(x))\n",
    "        les = int(np.round(le, prec))\n",
    "        ues = int(np.round(ue, prec))\n",
    "    else:\n",
    "        s += str(np.round(x, prec))\n",
    "        les = np.round(le, prec)\n",
    "        ues = np.round(ue, prec)\n",
    "    ret = f'${s}^' + '{+' + str(ues) + '}_{-' + str(les) + '}$'\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_plot_summary = samples_plot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.quantile(samples_plot_summary, [0.16, 0.5, 0.84], axis=0)\n",
    "median_values = a[1]\n",
    "upper_errors = a[2] - a[1]\n",
    "lower_error = a[1] - a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_values, upper_errors, lower_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(median_values)):\n",
    "    x = median_values[i]\n",
    "    ue = upper_errors[i]\n",
    "    le = lower_error[i]\n",
    "    print(get_err_string(x, le, ue))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
